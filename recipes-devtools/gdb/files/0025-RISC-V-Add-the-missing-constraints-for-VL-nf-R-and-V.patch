From 03a170a6d30138901805e77e48c00085573a409a Mon Sep 17 00:00:00 2001
From: Nelson Chu <nelson.chu@sifive.com>
Date: Thu, 13 Aug 2020 17:03:26 +0800
Subject: [PATCH 25/48] RISC-V: Add the missing constraints for VL<nf>R and
 VS<nf>R.

The destination vector register must be aligned to <nf>.  The <nf>
is 1, 2, 4, 8 for now.  Besides, under the aligned constraints, it
is impossible to use the registers that don't exist (number > 31).

	opcodes/
	* riscv-opc.c (match_vls_nf_rv): New function.  It is used to
	check the constraints for VL<nf>R and VS<nf>R.
	(riscv_opcodes): Updated the match_func for VL<nf>R and VS<nf>R.

	gas/
	* testsuite/gas/riscv/vector-insns-fail-load-store.l: Add the
	unaligned failed cases for VL<nf>R and VS<nf>R.
	* testsuite/gas/riscv/vector-insns-fail-load-store.s: Likewise.
---
 .../gas/riscv/vector-insns-fail-load-store.l  |  30 +++++
 .../gas/riscv/vector-insns-fail-load-store.s  |  38 +++++++
 opcodes/riscv-opc.c                           | 103 ++++++++++--------
 3 files changed, 127 insertions(+), 44 deletions(-)

diff --git a/gas/testsuite/gas/riscv/vector-insns-fail-load-store.l b/gas/testsuite/gas/riscv/vector-insns-fail-load-store.l
index bd04cbb263..406d79e2b2 100644
--- a/gas/testsuite/gas/riscv/vector-insns-fail-load-store.l
+++ b/gas/testsuite/gas/riscv/vector-insns-fail-load-store.l
@@ -555,3 +555,33 @@
 .*Error: illegal operands `vlxseg8ei1024.v v0,\(a0\),v4,v0.t'
 .*Error: illegal operands `vsxseg8ei1024.v v4,\(a0\),v4'
 .*Error: illegal operands `vsxseg8ei1024.v v0,\(a0\),v4,v0.t'
+.*Error: illegal operands `vl2r.v v31,\(a0\)'
+.*Error: illegal operands `vl2re8.v v31,\(a0\)'
+.*Error: illegal operands `vl2re16.v v31,\(a0\)'
+.*Error: illegal operands `vl2re32.v v31,\(a0\)'
+.*Error: illegal operands `vl2re64.v v31,\(a0\)'
+.*Error: illegal operands `vl2re128.v v31,\(a0\)'
+.*Error: illegal operands `vl2re256.v v31,\(a0\)'
+.*Error: illegal operands `vl2re512.v v31,\(a0\)'
+.*Error: illegal operands `vl2re1024.v v31,\(a0\)'
+.*Error: illegal operands `vl4r.v v30,\(a0\)'
+.*Error: illegal operands `vl4re8.v v30,\(a0\)'
+.*Error: illegal operands `vl4re16.v v30,\(a0\)'
+.*Error: illegal operands `vl4re32.v v30,\(a0\)'
+.*Error: illegal operands `vl4re64.v v30,\(a0\)'
+.*Error: illegal operands `vl4re128.v v30,\(a0\)'
+.*Error: illegal operands `vl4re256.v v30,\(a0\)'
+.*Error: illegal operands `vl4re512.v v30,\(a0\)'
+.*Error: illegal operands `vl4re1024.v v30,\(a0\)'
+.*Error: illegal operands `vl8r.v v26,\(a0\)'
+.*Error: illegal operands `vl8re8.v v26,\(a0\)'
+.*Error: illegal operands `vl8re16.v v26,\(a0\)'
+.*Error: illegal operands `vl8re32.v v26,\(a0\)'
+.*Error: illegal operands `vl8re64.v v26,\(a0\)'
+.*Error: illegal operands `vl8re128.v v26,\(a0\)'
+.*Error: illegal operands `vl8re256.v v26,\(a0\)'
+.*Error: illegal operands `vl8re512.v v26,\(a0\)'
+.*Error: illegal operands `vl8re1024.v v26,\(a0\)'
+.*Error: illegal operands `vs2r.v v31,\(a0\)'
+.*Error: illegal operands `vs4r.v v30,\(a0\)'
+.*Error: illegal operands `vs8r.v v26,\(a0\)'
diff --git a/gas/testsuite/gas/riscv/vector-insns-fail-load-store.s b/gas/testsuite/gas/riscv/vector-insns-fail-load-store.s
index 05f9358aed..e4f1085174 100644
--- a/gas/testsuite/gas/riscv/vector-insns-fail-load-store.s
+++ b/gas/testsuite/gas/riscv/vector-insns-fail-load-store.s
@@ -608,3 +608,41 @@
 	vlxseg8ei1024.v v0, (a0), v4, v0.t
 	vsxseg8ei1024.v v4, (a0), v4
 	vsxseg8ei1024.v v0, (a0), v4, v0.t
+
+# Vector Load/Store Whole Register Instructions
+
+	vl1r.v v31, (a0)		# OK
+
+	vl2r.v v31, (a0)		# vd must be aligned to 2
+	vl2re8.v v31, (a0)
+	vl2re16.v v31, (a0)
+	vl2re32.v v31, (a0)
+	vl2re64.v v31, (a0)
+	vl2re128.v v31, (a0)
+	vl2re256.v v31, (a0)
+	vl2re512.v v31, (a0)
+	vl2re1024.v v31, (a0)
+
+	vl4r.v v30, (a0)		# vd must be aligned to 4
+	vl4re8.v v30, (a0)
+	vl4re16.v v30, (a0)
+	vl4re32.v v30, (a0)
+	vl4re64.v v30, (a0)
+	vl4re128.v v30, (a0)
+	vl4re256.v v30, (a0)
+	vl4re512.v v30, (a0)
+	vl4re1024.v v30, (a0)
+
+	vl8r.v v26, (a0)		# vd must be aligned to 8
+	vl8re8.v v26, (a0)
+	vl8re16.v v26, (a0)
+	vl8re32.v v26, (a0)
+	vl8re64.v v26, (a0)
+	vl8re128.v v26, (a0)
+	vl8re256.v v26, (a0)
+	vl8re512.v v26, (a0)
+	vl8re1024.v v26, (a0)
+
+	vs2r.v v31, (a0)		# vs3 must be aligned to 2
+	vs4r.v v30, (a0)		# vs3 must be aligned to 4
+	vs8r.v v26, (a0)		# vs3 must be aligned to 8
diff --git a/opcodes/riscv-opc.c b/opcodes/riscv-opc.c
index 58190fd7c9..843b94aa46 100644
--- a/opcodes/riscv-opc.c
+++ b/opcodes/riscv-opc.c
@@ -453,6 +453,21 @@ match_vd_neq_vm (const struct riscv_opcode *op,
   return match_opcode (op, insn, 0);
 }
 
+static int
+match_vls_nf_rv (const struct riscv_opcode *op,
+		 insn_t insn,
+		 int constraints)
+{
+  int vd = (insn & MASK_VD) >> OP_SH_VD;
+  int nf = ((insn & (0x7 << 29) ) >> 29) + 1;
+
+  if (constraints
+      && ((vd % nf) != 0))
+    return 0;
+
+  return match_opcode (op, insn, 0);
+}
+
 static int
 match_vmv_nf_rv (const struct riscv_opcode *op,
 		 insn_t insn,
@@ -1543,50 +1558,50 @@ const struct riscv_opcode riscv_opcodes[] =
 {"vlseg7e1024ff.v",  0, INSN_CLASS_V_OR_ZVLSSEG,  "Vd,0(s)Vm", MATCH_VLSEG7E1024FFV, MASK_VLSEG7E1024FFV, match_vd_neq_vm, INSN_DREF },
 {"vlseg8e1024ff.v",  0, INSN_CLASS_V_OR_ZVLSSEG,  "Vd,0(s)Vm", MATCH_VLSEG8E1024FFV, MASK_VLSEG8E1024FFV, match_vd_neq_vm, INSN_DREF },
 
-{"vl1r.v",      0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE8V, MASK_VL1RE8V, match_opcode, INSN_DREF|INSN_ALIAS },
-{"vl1re8.v",    0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE8V, MASK_VL1RE8V, match_opcode, INSN_DREF },
-{"vl1re16.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE16V, MASK_VL1RE16V, match_opcode, INSN_DREF },
-{"vl1re32.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE32V, MASK_VL1RE32V, match_opcode, INSN_DREF },
-{"vl1re64.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE64V, MASK_VL1RE64V, match_opcode, INSN_DREF },
-{"vl1re128.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE128V, MASK_VL1RE128V, match_opcode, INSN_DREF },
-{"vl1re256.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE256V, MASK_VL1RE256V, match_opcode, INSN_DREF },
-{"vl1re512.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE512V, MASK_VL1RE512V, match_opcode, INSN_DREF },
-{"vl1re1024.v", 0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE1024V, MASK_VL1RE1024V, match_opcode, INSN_DREF },
-
-{"vl2r.v",      0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE8V, MASK_VL2RE8V, match_opcode, INSN_DREF|INSN_ALIAS },
-{"vl2re8.v",    0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE8V, MASK_VL2RE8V, match_opcode, INSN_DREF },
-{"vl2re16.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE16V, MASK_VL2RE16V, match_opcode, INSN_DREF },
-{"vl2re32.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE32V, MASK_VL2RE32V, match_opcode, INSN_DREF },
-{"vl2re64.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE64V, MASK_VL2RE64V, match_opcode, INSN_DREF },
-{"vl2re128.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE128V, MASK_VL2RE128V, match_opcode, INSN_DREF },
-{"vl2re256.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE256V, MASK_VL2RE256V, match_opcode, INSN_DREF },
-{"vl2re512.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE512V, MASK_VL2RE512V, match_opcode, INSN_DREF },
-{"vl2re1024.v", 0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE1024V, MASK_VL2RE1024V, match_opcode, INSN_DREF },
-
-{"vl4r.v",      0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE8V, MASK_VL4RE8V, match_opcode, INSN_DREF|INSN_ALIAS },
-{"vl4re8.v",    0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE8V, MASK_VL4RE8V, match_opcode, INSN_DREF },
-{"vl4re16.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE16V, MASK_VL4RE16V, match_opcode, INSN_DREF },
-{"vl4re32.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE32V, MASK_VL4RE32V, match_opcode, INSN_DREF },
-{"vl4re64.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE64V, MASK_VL4RE64V, match_opcode, INSN_DREF },
-{"vl4re128.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE128V, MASK_VL4RE128V, match_opcode, INSN_DREF },
-{"vl4re256.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE256V, MASK_VL4RE256V, match_opcode, INSN_DREF },
-{"vl4re512.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE512V, MASK_VL4RE512V, match_opcode, INSN_DREF },
-{"vl4re1024.v", 0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE1024V, MASK_VL4RE1024V, match_opcode, INSN_DREF },
-
-{"vl8r.v",      0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE8V, MASK_VL8RE8V, match_opcode, INSN_DREF|INSN_ALIAS },
-{"vl8re8.v",    0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE8V, MASK_VL8RE8V, match_opcode, INSN_DREF },
-{"vl8re16.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE16V, MASK_VL8RE16V, match_opcode, INSN_DREF },
-{"vl8re32.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE32V, MASK_VL8RE32V, match_opcode, INSN_DREF },
-{"vl8re64.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE64V, MASK_VL8RE64V, match_opcode, INSN_DREF },
-{"vl8re128.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE128V, MASK_VL8RE128V, match_opcode, INSN_DREF },
-{"vl8re256.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE256V, MASK_VL8RE256V, match_opcode, INSN_DREF },
-{"vl8re512.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE512V, MASK_VL8RE512V, match_opcode, INSN_DREF },
-{"vl8re1024.v", 0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE1024V, MASK_VL8RE1024V, match_opcode, INSN_DREF },
-
-{"vs1r.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VS1RV, MASK_VS1RV, match_opcode, INSN_DREF },
-{"vs2r.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VS2RV, MASK_VS2RV, match_opcode, INSN_DREF },
-{"vs4r.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VS4RV, MASK_VS4RV, match_opcode, INSN_DREF },
-{"vs8r.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VS8RV, MASK_VS8RV, match_opcode, INSN_DREF },
+{"vl1r.v",      0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE8V, MASK_VL1RE8V, match_vls_nf_rv, INSN_DREF|INSN_ALIAS },
+{"vl1re8.v",    0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE8V, MASK_VL1RE8V, match_vls_nf_rv, INSN_DREF },
+{"vl1re16.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE16V, MASK_VL1RE16V, match_vls_nf_rv, INSN_DREF },
+{"vl1re32.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE32V, MASK_VL1RE32V, match_vls_nf_rv, INSN_DREF },
+{"vl1re64.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE64V, MASK_VL1RE64V, match_vls_nf_rv, INSN_DREF },
+{"vl1re128.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE128V, MASK_VL1RE128V, match_vls_nf_rv, INSN_DREF },
+{"vl1re256.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE256V, MASK_VL1RE256V, match_vls_nf_rv, INSN_DREF },
+{"vl1re512.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE512V, MASK_VL1RE512V, match_vls_nf_rv, INSN_DREF },
+{"vl1re1024.v", 0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL1RE1024V, MASK_VL1RE1024V, match_vls_nf_rv, INSN_DREF },
+
+{"vl2r.v",      0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE8V, MASK_VL2RE8V, match_vls_nf_rv, INSN_DREF|INSN_ALIAS },
+{"vl2re8.v",    0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE8V, MASK_VL2RE8V, match_vls_nf_rv, INSN_DREF },
+{"vl2re16.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE16V, MASK_VL2RE16V, match_vls_nf_rv, INSN_DREF },
+{"vl2re32.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE32V, MASK_VL2RE32V, match_vls_nf_rv, INSN_DREF },
+{"vl2re64.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE64V, MASK_VL2RE64V, match_vls_nf_rv, INSN_DREF },
+{"vl2re128.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE128V, MASK_VL2RE128V, match_vls_nf_rv, INSN_DREF },
+{"vl2re256.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE256V, MASK_VL2RE256V, match_vls_nf_rv, INSN_DREF },
+{"vl2re512.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE512V, MASK_VL2RE512V, match_vls_nf_rv, INSN_DREF },
+{"vl2re1024.v", 0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL2RE1024V, MASK_VL2RE1024V, match_vls_nf_rv, INSN_DREF },
+
+{"vl4r.v",      0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE8V, MASK_VL4RE8V, match_vls_nf_rv, INSN_DREF|INSN_ALIAS },
+{"vl4re8.v",    0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE8V, MASK_VL4RE8V, match_vls_nf_rv, INSN_DREF },
+{"vl4re16.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE16V, MASK_VL4RE16V, match_vls_nf_rv, INSN_DREF },
+{"vl4re32.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE32V, MASK_VL4RE32V, match_vls_nf_rv, INSN_DREF },
+{"vl4re64.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE64V, MASK_VL4RE64V, match_vls_nf_rv, INSN_DREF },
+{"vl4re128.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE128V, MASK_VL4RE128V, match_vls_nf_rv, INSN_DREF },
+{"vl4re256.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE256V, MASK_VL4RE256V, match_vls_nf_rv, INSN_DREF },
+{"vl4re512.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE512V, MASK_VL4RE512V, match_vls_nf_rv, INSN_DREF },
+{"vl4re1024.v", 0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL4RE1024V, MASK_VL4RE1024V, match_vls_nf_rv, INSN_DREF },
+
+{"vl8r.v",      0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE8V, MASK_VL8RE8V, match_vls_nf_rv, INSN_DREF|INSN_ALIAS },
+{"vl8re8.v",    0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE8V, MASK_VL8RE8V, match_vls_nf_rv, INSN_DREF },
+{"vl8re16.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE16V, MASK_VL8RE16V, match_vls_nf_rv, INSN_DREF },
+{"vl8re32.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE32V, MASK_VL8RE32V, match_vls_nf_rv, INSN_DREF },
+{"vl8re64.v",   0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE64V, MASK_VL8RE64V, match_vls_nf_rv, INSN_DREF },
+{"vl8re128.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE128V, MASK_VL8RE128V, match_vls_nf_rv, INSN_DREF },
+{"vl8re256.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE256V, MASK_VL8RE256V, match_vls_nf_rv, INSN_DREF },
+{"vl8re512.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE512V, MASK_VL8RE512V, match_vls_nf_rv, INSN_DREF },
+{"vl8re1024.v", 0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VL8RE1024V, MASK_VL8RE1024V, match_vls_nf_rv, INSN_DREF },
+
+{"vs1r.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VS1RV, MASK_VS1RV, match_vls_nf_rv, INSN_DREF },
+{"vs2r.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VS2RV, MASK_VS2RV, match_vls_nf_rv, INSN_DREF },
+{"vs4r.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VS4RV, MASK_VS4RV, match_vls_nf_rv, INSN_DREF },
+{"vs8r.v",  0, INSN_CLASS_V,  "Vd,0(s)", MATCH_VS8RV, MASK_VS8RV, match_vls_nf_rv, INSN_DREF },
 
 {"vamoaddei8.v",   0, INSN_CLASS_V_OR_ZVAMO,  "Ve,0(s),Vt,VfVm", MATCH_VAMOADDEI8V, MASK_VAMOADDEI8V, match_vd_neq_vm, INSN_DREF},
 {"vamoswapei8.v",  0, INSN_CLASS_V_OR_ZVAMO,  "Ve,0(s),Vt,VfVm", MATCH_VAMOSWAPEI8V, MASK_VAMOSWAPEI8V, match_vd_neq_vm, INSN_DREF},
-- 
2.33.0

